{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Neural Networks and Deep Learning (CSCI 5922)</center>\n",
    "# <center> Spring 2019 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this assignment is to introduce neural networks in terms of ideas you are already familiar with:  linear regression and linear-threshold classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a dataset with 2 input variables ($x_1$, $x_2$) and an output variable ($y$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data = np.loadtxt(os.path.join('data', 'assign1_data.txt'))\n",
    "X = data[:,:2]\n",
    "y = data[:, 2]\n",
    "z = data[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to find the least squares solution to $y = w_1 x_1 + w_2 x_2 + b$ for the above dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following function below and use it to answer questions (A) and (B). \n",
    "\n",
    "**Note:** Please do not change the interface of the given function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lms(X, y):\n",
    "    \"\"\"\n",
    "    Finds the Least Mean Squares solution\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : NumPy array of features (size : no of examples X features)\n",
    "    y : Numpy array of output value 'y' (size : no of examples X 1)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : solution array\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A) Report the values of $w_1$, $w_2$, and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) What function or method did you use to find the least-squares solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the LMS algorithm, write a program that determines the coefficients {w1,w2,b} via incremental updating, steepest descent, and multiple passes through the training data. You will need to experiment with updating rules (online, batch, minibatch), step sizes (i.e., learning rates), stopping criteria, etc. Experiment to find settings that lead to solutions with the fewest number of sweeps through the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following functions below and use them to answer questions (A), (B) and (C). You may find the shuffle function from scikit-learn useful. \n",
    "\n",
    "Use the following hyperparameters:\n",
    "\n",
    "Learning rates = [0.001, 0.05, 0.01, 0.05, 0.1, 0.3]\n",
    "\n",
    "MaxIter = [10, 50, 100, 500, 1000, 5000, 10000, 25000, 50000]\n",
    "\n",
    "**Note:** Please do not change the interface of the given functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def online_update(X, y, w):\n",
    "    \"\"\"\n",
    "    One iteration of the online update over the entire dataset (one sweep of the dataset).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : NumPy array of features (size : no of examples X features)\n",
    "    y : Numpy array of class labels (size : no of examples X 1)\n",
    "    w : array of coefficients from the previous iteration\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : Coefficients of the classifier (after updating)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def batch_update(X, y, w):\n",
    "    \"\"\"\n",
    "    One iteration of the batch update.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : NumPy array of features (size : no of examples X features)\n",
    "    y : Numpy array of class labels (size : no of examples X 1)\n",
    "    w : array of coefficients from the previous iteration\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : Coefficients of the classifier (after updating)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def mini_batch_update(X, y, w, batch_size):\n",
    "    \"\"\"\n",
    "    One iteration of the mini-batch update over the entire dataset (one sweep of the dataset).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : NumPy array of features (size : no of examples X features)\n",
    "    y : Numpy array of class labels (size : no of examples X 1)\n",
    "    w : array of coefficients from the previous iteration\n",
    "    batch_size : size of the batch for gradient update\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : Coefficients of the classifier (after updating)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def lms_grad_desc(X, y, maxIter, alpha, update, *batch_size):\n",
    "    \"\"\"\n",
    "    Implements the LMS with gradient descent.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : NumPy array of features (size : no of examples X features)\n",
    "    y : Numpy array of class labels (size : no of examples X 1)\n",
    "    maxIter : Maximum number of iterations allowed\n",
    "    alpha : Learning rate\n",
    "    update : update function to utilize (one of online, batch, mini-batch)\n",
    "    batch_size : number of examples in a batch (only useful when update = mini_batch_update)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : Coefficients of the classifier (after updating)\n",
    "    \n",
    "    Note : *batch_size is an optional argument and only to be used when doing mini-batch Gradient Descent \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A) Report the values of $w_1$, $w_2$, and $b$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) What settings worked well for you:  online vs. batch vs. minibatch? What step size? How did you decide to terminate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) Make a graph of error on the entire data set as a function of epoch. An epoch is a complete sweep through all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set from a regression problem can be converted into a classification problem simply by using the sign of (+ or -) as representing one of two classes. In the data set used in Part 1 and 2, you'll see a variable that represents this binary (0 or 1) class.\n",
    "\n",
    "Use the perceptron learning rule to solve for the coefficients {$w_1$, $w_2$, $b$} of this classification problem.   \n",
    "\n",
    "Two warnings: First, your solution to Part 3 should require only a few lines of code changed from the code you wrote for Part 2. Second, the Perceptron algorithm will not converge if there is no exact solution to the training data. It will jitter among coefficients that all yield roughly equally good solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following functions below and use them to answer questions (A) and (B). \n",
    "\n",
    "**Note:** Please do not change the interface of the given functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_update(X, y, w):\n",
    "    \"\"\"\n",
    "    One iteration of the Perceptron update over the entire dataset (not just a single point).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : NumPy array of features (size : no of examples X features)\n",
    "    y : Numpy array of class labels (size : no of examples X 1)\n",
    "    w : array of coefficients from the previous iteration\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : Coefficients of the classifier (after updating)\n",
    "    incorrect : Incorrectly classified examples\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def perceptron(X, y, maxIter, alpha):\n",
    "    \"\"\"\n",
    "    Implements the Perceptron algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : NumPy array of features (size : no of examples X features)\n",
    "    y : Numpy array of class labels (size : no of examples X 1)\n",
    "    maxIter : The maximum number of iterations allowed \n",
    "    alpha : Learning Rate\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : Coefficients of the classifier\n",
    "    incorrect : Incorrectly classified examples on termination\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A) Report the values of coefficients $w_1$, $w_2$, and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) Make a graph of the accuracy (% correct classification) on the training set as a function of epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, we really want to train a model based on some data and then expect the model to do well on \"out of sample\" data. Try this with the code you wrote for Part 3:  Train the model on the first {5, 10, 25, 50, 75} examples in the data set and test the model on the final 25 examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following function below and use it to answer (A). \n",
    "\n",
    "**Note:** Please do not change the interface of the given function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X, y, w):\n",
    "    \"\"\"\n",
    "    Use this function to classify examples in the test set\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : Test set features\n",
    "    y : Test set labels\n",
    "    w : Perceptron coefficients\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    correct : number of correctly classified examples\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does performance on the test set vary with the amount of training data? Make a bar graph showing performance for each of the different training set sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
